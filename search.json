[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Lecture #\nDate\nTopic\n\n\n\n\n1\n3 Jan\nIntroduction and Logistics [Slides]\n\n\nNone\n4 Jan\nPre-requisites quiz released\n\n\n2\n5 Jan\nConvention, Metrics, Classification, Regression [Slides]\n\n\n3\n10 Jan\nDecision Trees - 1[Slides][Notebook]\n\n\n4\n12 Jan\nDecision Trees - 2[Slides][Notebook]\n\n\n5\n17 Jan\nBias and Variance[Slides][Notebook on Python utils][Notebook on Grid Search]\n\n\nNone\n18 Jan\nQuiz 1\n\n\n6\n19 Jan\nBias, Variance 2, Cross Validation[Slides]\n\n\n7\n24 Jan\nEnsemble Methods[Slides]\n\n\n8\n31 Jan\nEnsemble Methods[Slides], Weighted samples in decision trees[Slides], Maths for ML-1 [Slides] [Notebook-1] [Notebook 2], [Streamlit app] Linear Regression [Slides]\n\n\n9\n2 Feb\nLinear Regression [Slides], Contour Plots [Slides], Geometric View of Linear Regression [Slides]\n\n\n10\n9 Feb\nLinear Regression II [Slides]\n\n\n11\n14 Feb\nGradient Descent [Slides], Taylor’s Series, Notebook on Taylor’s series, Reference on relationship between Taylor’s series and GD, Reference 2\n\n\n12\n16 Feb\nGradient Descent [Slides] Notebook\n\n\n13\n21 Feb\nGradient Descent continued, [Ridge Regression], [Streamlit demo], [Additional reading on SGD being an unbiased estimator]\n\n\n14\n23 Feb\nRidge regression, LASSO, [Interactive article on Optimization algorithms]\n\n\n15\n28 Feb\nLogistic regression [Slides], [Notebook] (best run locally to render interactive visualisations)\n\n\n16\n2 Mar\nLogistic regression [Slides]\n\n\n17\n14 Mar\nLogistic regression [Slides]\n\n\n18\n16 Mar\nMLP [Slides]\n\n\n19\n21 Mar\nMLP [Slides], Notebook\n\n\n20\n28 Mar\nMLP [Slides]\n\n\n21\n30 Mar\nNext work prediction [Slides], Notebook\n\n\n22\n4 Apr\nConvolutional Neural Networks [Slides], 1d CNN slides, Notebook 1, Notebook 2, Notebook 3, Equivariance v/s Invariance, Reference1, Reference2, Notebook\n\n\n23\n6 Apr\nAutograd [Slides], Notebook on Autodiff, Reference on chain rule Naive Bayes [Slides]\n\n\n24\n11 Apr\nNaive Bayes [Slides], KNN [Slides]\n\n\n25\n13 Apr\nKNN, Parametric v/s Non-Parametric, Movie Recommendation\n\n\n26\n18 Apr\nCurse of Dimensionality, Segment Anything demo, Unsupervised learning, Image segmentation, Image completion, KMeans Viz 1, Viz 2, PCA reference\n\n\n27\n20 Apr\nConstrained Optimization (self study), Support Vector Machines -1\n\n\n28\n23 Apr\nSupport Vector Machines\n\n\n29\n25 Apr\nSupport Vector Machines (Soft Margin)"
  },
  {
    "objectID": "grading.html",
    "href": "grading.html",
    "title": "Grading Policy",
    "section": "",
    "text": "Quizzes: 48%\n\n16% each\nBest 3 out of 4\nIf you miss a single quiz for any reason, there will be no makeups\n\n\n\n\nAssignments: 44%\n\n4 or 5 assignments\nDone in groups of 5\nAtleast one question per assignment will be a project-like question\nVariable weight (e.g. some assignments would be 10%, some 12%, etc.)\nSome assignments would involve:\n\nMaking pull requests to public repositories\nWriting Hugging Face Spaces like demos\n\n\n\n\n\nAttendance: 8%\n\n&lt;= 3 absences: 8%\n4 or 5 absences: 7%\n6 or 7 absences: 6%\n8 or 9 absences: 4%\n10 or 11 absences: 2%\n12 or more absences: 0%"
  },
  {
    "objectID": "quizzes.html",
    "href": "quizzes.html",
    "title": "Quizzes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 30, 2023\n\n\nPrerequsite test\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ES 335 Machine Learning",
    "section": "",
    "text": "Please join the Slack channel for the course.\n\n\n\n\n\n\nSummary\n\n\n\n\nInstructor: Nipun Batra (nipun.batra@iitgn.ac.in)\nTeaching Assistants: Rishiraj Adhikary, Ayush Shrivastava\nCourse Timings:\n\nLectures: Monday, Wednesday 8:30 AM to 10 AM in 10/103\nTutorials: Friday: 1130 to 1 PM in 10/103\n\n\n\n\n\n\n\n\n\n\nPre-requisite exam\n\n\n\nThe pre-requisite exam has to be submitted by 6th January 2024, 9 PM. Details on how to submit the exam are given in the exam itself. The exam is open book and open internet.\n\n\n\n\nPre-requisites:\n\nGood experience in Python programming\nProbability\nLinear Algebra\n\nCourse preparation: Students are encouraged to study some of the following to refresh their understanding of some of the prerequisities before the course formally begins.\n\nFirst four chapters of the Python Data Science handbook\nSome material on Linear Algebra\nKhan academy course on Stats and Probability\n\n\n\nReference textbooks:\n\nGareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. An Introduction to Statistical Learning with Applications in R\nChristopher Bishop. Pattern Recognition and Machine Learning. Springer, 2006.[Freely available online]\nFriedman J, Hastie T, Tibshirani R. The elements of statistical learning. New York, NY, USA:: Springer series in statistics; 2001.[Freely available online]\nDuda RO, Hart PE, Stork DG. Pattern classification. John Wiley & Sons; 2012 Nov 9.\nMitchell TM. Machine learning. 1997. Burr Ridge, IL: McGraw Hill. 1997;45(37):870-7.\nMurphy, K. Machine Learning: A Probabilistic Perspective. MIT Press\nGoodfellow I, Bengio Y, Courville A, Bengio Y. Deep learning. Cambridge: MIT press; 2016 Nov 18.[Freely available online]\n\n\n\nSome other ML courses\n\nNPTEL course by Balaram Ravindran\nCMU course by Tom Mitchell and Maria-Florina Balcan\nCoursera ML course by Andrew Ng\nFAST.ai course on ML\nPractical deep learning for coders by FAST.ai\nCourse by Alex Ihler, UCI"
  },
  {
    "objectID": "exams/prereq.html",
    "href": "exams/prereq.html",
    "title": "Prerequsite test",
    "section": "",
    "text": "Instructions\n\nThis test is open book, open internet, open notes. You can use any resources you want to solve the problems.\nYou should be typing your answers in a Jupyter notebook.\nThe submission would be a link to a public GitHub repository containing the notebook. Fill this form to submit your solution.\nA random subset of students may have a viva post the exam. The viva would be based on the notebook and the solutions you have provided.\nThe test is open till 6th January 2024 9 PM. You can submit your solutions anytime before that.\nThis problem has to be solved individually. You cannot collaborate with anyone else.\nThe code should be written using Python.\nSome questions may require you to answer in text. You can use markdown cells to write your answers. Some questions may require you to write code. You can use code cells to write your code. Some questions may require you to write mathematical expressions. You can use LaTeX to write your expressions. You can write such LaTeX expressions in markdown cells.\nFor any other questions, please ask on the General channel on Slack.\n\n\n\n\nQuestions\n\nHow many multiplications and additions do you need to perform a matrix multiplication between a (n, k) and (k, m) matrix? Explain.\nWrite Python code to multiply the above two matrices. Solve using list of lists and then use numpy. Compare the timing of both solutions. Which one is faster? Why?\nFinding the highest element in a list requires one pass of the array. Finding the second highest element requires 2 passes of the the array. Using this method, what is the time complexity of finding the median of the array? Can you suggest a better method? Can you implement both these methods in Python and compare against numpy.median routine in terms of time?\nWhat is the gradient of the following function with respect to x and y? \\[\nx^2y+y^3\\sin(x)\n\\]\nUse JAX to confirm the gradient evaluated by your method matches the analytical solution corresponding to a few random values of x and y\nUse sympy to confirm that you obtain the same gradient analytically.\nCreate a Python nested dictionary to represent hierarchical information. We want to store record of students and their marks. Something like:\n\n2022\n\nBranch 1\n\nRoll Number: 1, Name: N, Marks:\n\nMaths: 100, English: 70 …\n\n\nBranch 2\n\n2023\n\nBranch 1\nBranch 2\n\n2024\n\nBranch 1\nBranch 2\n\n2025\n\nBranch 1\nBranch 2\n\n\nStore the same information using Python classes. We have an overall database which is a list of year objects. Each year contains a list of branches. Each branch contains a list of students. Each student has some properties like name, roll number and has marks in some subjects.\nUsing matplotlib plot the following functions on the domain: x = 0.5 to 100.0 in steps of 0.5.\n\n\\(y = x\\)\n\\(y = x^2\\)\n\\(y = \\frac{x^3}{100}\\)\n\\(y = \\sin(x)\\)\n\\(y = \\frac{\\sin(x)}{x}\\)\n\\(y = \\log(x)\\)\n\\(y = e^x\\)\n\nUsing numpy generate a matrix of size 20X5 containing random numbers drawn uniformly from the range of 1 to 2. Using Pandas create a dataframe out of this matrix. Name the columns of the dataframe as “a”, “b”, “c”, “d”, “e”. Find the column with the highest standard deviation. Find the row with the lowest mean.\nAdd a new column to the dataframe called “f” which is the sum of the columns “a”, “b”, “c”, “d”, “e”. Create another column called “g”. The value in the column “g” should be “LT8” if the value in the column “f” is less than 8 and “GT8” otherwise. Find the number of rows in the dataframe where the value in the column “g” is “LT8”. Find the standard deviation of the column “f” for the rows where the value in the column “g” is “LT8” and “GT8” respectively.\nWrite a small piece of code to explain broadcasting in numpy.\nWrite a function to compute the argmin of a numpy array. The function should take a numpy array as input and return the index of the minimum element. You can use the np.argmin function to verify your solution."
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Projects\n\nIs there a project component in the course?\n\nYes and No. We will have a project-like question in each of your assignments. This will be a more “structured” project in that sense and all students would have the same question. However, there is no separate project component in the course. We feel this will help you get a better understanding of the concepts covered in the course, and the added structure will help you get started with the project.\n\nCan you give an example of the project question?\n\nSure. We will build an activity classifier: walking, running, etc. Initially, we use publicly available datasets to build the classifier. We will then help you with collecting your data using your smartphone and build a classifier using your data. Those who want to go beyond the learning objectives, can deploy the classifier on your smartphone.\n\n\n\n\n\nPrerequisites\n\nWhat are the course prerequisites?\n\nThe course has no “formal” prerequisites like all courses at IITGn. However, it is assumed that you have a basic understanding of:\n\nprogramming (Python), and data structures (ES242 equivalent)\nprobability and statistics\nlinear algebra\ncalculus\n\n\nWhat is the prerequisite exam?\n\nThis is an exam that we have designed to ensure that you have the necessary background to take the course.\n\nHow can I prepare for the prerequisite exam?\n\nYour UG course material should be sufficient to prepare for the exam.\nYou may additionally refer to the “prerequisite” reading section on the course homepage.\n\nWhat happens if I do not clear the prerequisite exam?\n\nYou will not be allowed to take the course.\n\nWhat do you mean by “clear” the exam?\n\nLike all courses at IITGn, the instructor will decide the cut-off for the exam. You will have to score above the cut-off to clear the exam. No cut-off will be revealed to the students apriori.\n\n\n\n\n\nQuizzes\n\nWhat happens if I miss a quiz due to any reason?\n\nThe quiz will be marked as 0.\nThe provision of best 3 out of 4 quizzes is designed keeping in mind such scenarios.\n\nWill the quizzes and end-semester exam be open book? Will I be allowed to carry notes?\n\nNo, the exams and quizzes will be closed book. You are not permitted to carry notes.\n\nHow soon can I expect to receive my answer sheets back?\n\nYou should expect to receive answer sheets back in 4-5 working days.\n\nIs there an end-semester exam or mid-semester exam?\n\n2 out of the 4 quizzes will be held in the mid-semester and end-semester slots. The remaining two quizzes will be held during the semester.\n\nWill the quizzes be MCQs or subjective?\n\nThe quizzes may contain both the MCQs and subjective questions.\n\n\n\n\n\nAssignments\n\nWhat happens if I miss an assignment due to any reason?\n\nThere will no extensions for assignments.\n\nI have a doubt in the assignment. Whom should I write to?\n\nAsk on the slack #assignments channel. If you don’t get a response within 2 days, write to the course instructor.\n\nI do not know Python. Can I code assignments in some other language?\n\nUnfortunately, no. You have to stick to Python.\n\nHow will you evaluate the assignment?\n\nThe assignments would be followed by a viva. The TAs would first check the code and compare against the submission. Any change from the submitted code is not allowed and any instance of the same would culminate in a warning. The TAs would run the code and ask a few questions. About 75% of these questions would be based on the assignment in question and about 25% would be based on the theory behind the concepts covered in the assignment.\nThe grade breakup would be: i) code runs correctly and solves the problem [50% marks]; ii) questions based on the assignment and student understanding of code [25% marks]; iii) code quality [12.5% marks]; iv) questions based on the theory behind the concepts covered in the assignments [12.5% marks]\n\nIs the assignment individual or group?\n\nThe assignment is group. In case of group, all team members get the same grade for the assignment.\n\n\n\n\n\nAttendance\n\nAttendance policy\n\nAttendance is mentioned in the grading policy clearly."
  }
]